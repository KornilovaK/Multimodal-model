{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from lightautoml.tasks import Task\n",
    "import lightautoml\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocess atributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_attributes(attributes, test):\n",
    "    attributes = attributes[(attributes.variantid.isin(test.variantid1) | attributes.variantid.isin(test.variantid2))]\n",
    "    model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')\n",
    "    attributes['characters'] = attributes.characteristic_attributes_mapping.progress_apply(lambda x: model.encode(x))\n",
    "    attributes[['variantid', 'characters']].to_parquet('data/processed/attributes.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(text, model, tokenizer):\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    emoji_pattern = re.compile(\"[\" \n",
    "                               u\"\\U0001F600-\\U0001F64F\"  \n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                               u\"\\U00002702-\\U000027B0\"  \n",
    "                               u\"\\U000024C2-\\U0001F251\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub(r'[$#@]', '', text)\n",
    "    text = re.sub(r'[^\\w\\s\\-.]', '', text)\n",
    "    \n",
    "    return model.encode(text)\n",
    "\n",
    "def process_text(df, test):\n",
    "    model = SentenceTransformer(\"cointegrated/rubert-tiny2\")\n",
    "\n",
    "    df = df[(df.variantid.isin(test.variantid1) | df.variantid.isin(test.variantid2))].fillna('')\n",
    "    df.description = df.description.apply(lambda x: clean_description(x, model))\n",
    "    \n",
    "    df[['variantid', 'name_bert_64', 'description']].to_parquet('data/processed/text.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resnet(resnet, test):\n",
    "    resnet = resnet[(resnet.variantid.isin(test.variantid1) | resnet.variantid.isin(test.variantid2))].fillna('')\n",
    "    \n",
    "    resnet['len_emb_not_main'] = resnet.pic_embeddings_resnet_v1.apply(lambda x: len(x))   \n",
    "    resnet['pca_not_main'] = resnet.apply(lambda x: pca_transform(x.pic_embeddings_resnet_v1) if x.len_emb_not_main > 0 else np.zeros(128), axis=1)\n",
    "    resnet.main_pic_embeddings_resnet_v1 = resnet.main_pic_embeddings_resnet_v1.apply(lambda x: x[0])\n",
    "    resnet[['variantid', 'main_pic_embeddings_resnet_v1', 'pca_not_main']].to_parquet('data/processed/resnet.parquet')\n",
    "\n",
    "def pca_transform(row):\n",
    "    n = row.shape[0]\n",
    "    x = np.concatenate(row, axis=0).reshape(n, 128).T\n",
    "    pca = PCA(n_components=1)\n",
    "    x_transformed = pca.fit_transform(x)\n",
    "    \n",
    "    return np.concatenate(x_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_parquet('data/raw/attributes.parquet')\n",
    "resnet = pd.read_parquet('data/raw/resnet.parquet')\n",
    "text_and_bert = pd.read_parquet('data/raw/text_and_bert.parquet')\n",
    "\n",
    "train = pd.read_parquet('data/raw/train.parquet')\n",
    "test = pd.read_parquet('data/raw/test.parquet')\n",
    "train = train[~((train.variantid1.isin(test.variantid1)) | (train.variantid2.isin(test.variantid2)))]\n",
    "train.to_parquet('data/processed/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_resnet(resnet, test)\n",
    "process_text(text_and_bert, test)\n",
    "process_attributes(attributes, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_parquet('data/processed/attributes.parquet')\n",
    "resnet = pd.read_parquet('data/processed/resnet.parquet')\n",
    "text_and_bert = pd.read_parquet('data/processed/text.parquet')\n",
    "\n",
    "train = pd.read_parquet('data/processed/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = text_and_bert.rename(columns={'variantid': 'variantid1', 'description': 'description1', 'name_bert_64': 'name1'})\n",
    "temp1 = train.merge(temp1, how='inner', on='variantid1')\n",
    "temp2 = text_and_bert.rename(columns={'variantid': 'variantid2', 'description': 'description2', 'name_bert_64': 'name2'})\n",
    "df = temp1.merge(temp2, how='inner', on='variantid2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp1 = resnet.rename(columns={'variantid': 'variantid1', 'main_pic_embeddings_resnet_v1': 'main1', 'pca_not_main': 'not_main1'})\n",
    "temp1 = df.merge(temp1, how='inner', on='variantid1')\n",
    "temp2 = resnet.rename(columns={'variantid': 'variantid2', 'main_pic_embeddings_resnet_v1': 'main2', 'pca_not_main': 'not_main2'})\n",
    "df = temp1.merge(temp2, how='inner', on='variantid2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = attributes.rename(columns={'variantid': 'variantid1', 'characters': 'characters1'})\n",
    "temp1 = df.merge(temp1, how='inner', on='variantid1')\n",
    "temp2 = attributes.rename(columns={'variantid': 'variantid2', 'characters': 'characters2'})\n",
    "df = temp1.merge(temp2, how='inner', on='variantid2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('data/processed/merged.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal model -> binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.read_parquet('data/processed/merged.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.n = len(df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cur_df = self.df.iloc[idx]\n",
    "        main1, main2 = torch.Tensor(cur_df.main1), torch.Tensor(cur_df.main2) #main images\n",
    "        not_main1, not_main2 = torch.Tensor(cur_df.not_main1), torch.Tensor(cur_df.not_main2) # not main images\n",
    "        attr1, attr2 = torch.tensor(cur_df.characters1), torch.tensor(cur_df.characters2) # attributes\n",
    "        description1, description2 = torch.Tensor(cur_df.description1), torch.Tensor(cur_df.description2) # descriptions\n",
    "        name1, name2 = torch.Tensor(cur_df.name1), torch.Tensor(cur_df.name2) # names\n",
    "\n",
    "        labels = torch.tensor(cur_df.target)\n",
    "        \n",
    "        return main1, main2, not_main1, not_main2, attr1, attr2, description1, description2, name1, name2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "description_size = 312\n",
    "name_size = 64\n",
    "attribute_size = 512\n",
    "embedding_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio, validation_ratio, test_ratio = 0.75, 0.15, 0.10\n",
    "\n",
    "train, test = train_test_split(df, test_size=(1 - train_ratio), stratify=df.target)\n",
    "val, test = train_test_split(test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=test.target)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = MultimodalDataset(train), MultimodalDataset(val), MultimodalDataset(test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model params and architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, image_size=128, description_size=312, name_size=64, attribute_size=512, embedding_size=256, batch_size=32):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        \n",
    "        self.main_image = nn.Sequential( nn.Linear(image_size, embedding_size), nn.ReLU() ) # [b, 128] -> [b, 256] -> [b, 256, 1]\n",
    "        self.not_main_image = nn.Sequential( nn.Linear(image_size, embedding_size), nn.ReLU() ) # [b, 128] -> [b, 256] -> [b, 256, 1]\n",
    "        self.image_embedding = nn.Sequential( nn.Conv1d(embedding_size, 128, kernel_size=2), nn.ReLU() ) # [b, 256, 2] -> [b, 128, 1]\n",
    "\n",
    "        self.name = nn.Sequential( nn.Linear(name_size, embedding_size), nn.ReLU() ) # [b, 64] -> [b, 256] -> [b, 256, 1]\n",
    "        self.description = nn.Sequential( nn.Linear(description_size, embedding_size), nn.ReLU() ) # [b, 312] -> [b, 256] -> [b, 256, 1]\n",
    "        self.text_embedding = nn.Sequential( nn.Conv1d(embedding_size, 128, kernel_size=2), nn.ReLU() ) # [b, 256, 2] -> [b, 128, 1]\n",
    "        \n",
    "        self.tabular_embedding = nn.Sequential(\n",
    "            nn.Linear(attribute_size, embedding_size), # [b, 512] -> [b, 256]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, 128), # [b, 256] -> [b, 128]\n",
    "            nn.ReLU(),\n",
    "        ) # # [b, 128] -> [b, 128, 1]\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(128, 64, kernel_size=3), # [b, 128, 3] ->  [b, 64, 1] -> [b, 64]\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "            \n",
    "    def forward(self, main1, main2,\n",
    "                not_main1, not_main2,\n",
    "                attr1, attr2, description1,\n",
    "                description2, name1, name2):\n",
    "\n",
    "        main_img_emb1, main_img_emb2 = torch.unsqueeze(self.main_image(main1), 2), torch.unsqueeze(self.main_image(main2), 2)\n",
    "        img_emb1, img_emb2 = torch.unsqueeze(self.not_main_image(not_main1), 2), torch.unsqueeze(self.not_main_image(not_main2), 2)\n",
    "        \n",
    "        image_emb1 = self.image_embedding(torch.cat((main_img_emb1, img_emb1), dim=2))\n",
    "        image_emb2 = self.image_embedding(torch.cat((main_img_emb2, img_emb2), dim=2))\n",
    "\n",
    "        name_emb1, name_emb2 = torch.unsqueeze(self.name(name1), 2), torch.unsqueeze(self.name(name2), 2)\n",
    "        desc_emb1, desc_emb2 = torch.unsqueeze(self.description(description1), 2), torch.unsqueeze(self.description(description2), 2)\n",
    "        text_emb1 = self.text_embedding(torch.cat((name_emb1, desc_emb1), dim=2))\n",
    "        text_emb2 = self.text_embedding(torch.cat((name_emb2, desc_emb2), dim=2))\n",
    "\n",
    "        tab_emb1, tab_emb2 = torch.unsqueeze(self.tabular_embedding(attr1), 2), torch.unsqueeze(self.tabular_embedding(attr2), 2)\n",
    "                \n",
    "        combined1 = self.embedding(torch.cat((image_emb1, text_emb1, tab_emb1), dim=2))\n",
    "        combined2 = self.embedding(torch.cat((image_emb2, text_emb2, tab_emb2), dim=2))\n",
    "                                   \n",
    "        combined = torch.cat((torch.squeeze(combined1, 2), torch.squeeze(combined2, 2)), 1)\n",
    "        return self.fc(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contrastive_loss(distance, label, margin=1.0):\n",
    "#     loss = (1 - label) * torch.pow(distance, 2) + \\\n",
    "#            (label) * torch.pow(torch.clamp(margin - distance, min=0.0), 2)\n",
    "#     return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultimodalModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler1 = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "scheduler2 = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b5d3fae6f04856ab0f8a6f97ad268b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.8122291663285738. Loss: 0.5001284942341234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2093f903ec41f5a53de13b7e8db923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8383350108600488. Loss: 0.45312686761583254\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c100bd858a48dbaf6f623f6177379c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.8394318343247825. Loss: 0.4511466701186657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3197085b9fba461aadeec8efeb170841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8428385424944361. Loss: 0.4368260700989257\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964ac177ee07410c962dbb3faac91e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.8470553378927832. Loss: 0.4341748803712436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8e17b6545b4779b2bc2fc2ab035522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8457451212061587. Loss: 0.42841810517756224\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7043255c7c4c421b821a515a84564f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.8531292842151008. Loss: 0.4194670418698639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002f9da2c545459d9373810b67a0ee56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.852860141901173. Loss: 0.42525227484386857\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53ded7f53dd4672bec00d474f26bd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.8587729179645414. Loss: 0.4060947069344967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5775dde5c204f649944b47105f2bbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8500946700083609. Loss: 0.4201602909385962\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba5bf553e0e4aeebf5e9fa6b7db3b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.864624340527097. Loss: 0.3924646028319893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7e078571ce4bbaa1dcf4f09700c777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8512774420373559. Loss: 0.4156061605920224\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14f616f95364c919954e04b817fe2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.8720175099495444. Loss: 0.37505712212874237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12108bc218c44a4baa7b590781a04550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8618935861776558. Loss: 0.3985903608208814\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c16a19d6cb64abfa95e537a4b3f43e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.8790522485556045. Loss: 0.3588877206657029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea357e552af43e385937361cd61401a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8647188369933233. Loss: 0.39614918848699054\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117b74f6c8bb4730895e8a9f2b51d5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.8840405627434961. Loss: 0.3452025564528483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7db6873f9d94ed7820948e15bcc7c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8699260380255219. Loss: 0.3942302744733534\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796d51096e994792bb62d36ba4b34797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PR-AUC: 0.888389055406888. Loss: 0.3340813013032531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d63a2acb6c440cb84a3bea7da93450a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation PR-AUC: 0.8682331856774359. Loss: 0.3964038596161535\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_auc, valid_auc = 0.0, 0.0\n",
    "    train_losses, validation_losses = 0.0, 0.0\n",
    "    \n",
    "    n1, n2 = len(train_loader), len(val_loader)\n",
    "    print(f'Epoch {epoch}')\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        main1, main2, not_main1, not_main2, \\\n",
    "        attr1, attr2, description1, description2, \\\n",
    "        name1, name2, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(main1.to(device), main2.to(device),\n",
    "                not_main1.to(device), not_main2.to(device),\n",
    "                attr1.to(device), attr2.to(device), description1.to(device),\n",
    "                description2.to(device), name1.to(device), name2.to(device))\n",
    "\n",
    "        #distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss = criterion(output, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = np.argmax(F.softmax(output).cpu().detach().numpy(), axis=1)\n",
    "        preds = (y_pred > 0.5).astype(int)\n",
    "        precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "        train_auc += auc(recall, precision)\n",
    "        train_losses += loss.item()\n",
    "        \n",
    "    print(f'Training PR-AUC: {train_auc / n1}. Loss: {train_losses / n1}')\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(val_loader)):\n",
    "            main1, main2, not_main1, not_main2, \\\n",
    "            attr1, attr2, description1, description2, \\\n",
    "            name1, name2, labels = data\n",
    "            \n",
    "            output = model(main1.to(device), main2.to(device),\n",
    "                not_main1.to(device), not_main2.to(device),\n",
    "                attr1.to(device), attr2.to(device), description1.to(device),\n",
    "                description2.to(device), name1.to(device), name2.to(device))\n",
    "            \n",
    "            loss = criterion(output, labels.to(device))\n",
    "            y_pred = np.argmax(F.softmax(output).cpu().detach().numpy(), axis=1)\n",
    "            preds = (y_pred > 0.5).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "            valid_auc += auc(recall, precision)\n",
    "            validation_losses += loss.item()\n",
    "\n",
    "    print(f'Validation PR-AUC: {valid_auc / n2}. Loss: {validation_losses / n2}')\n",
    "\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'binary_classification.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a6f909006143b39f3aeb4c655df1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_auc = 0\n",
    "test_losses = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(test_loader)):\n",
    "        main1, main2, not_main1, not_main2, \\\n",
    "        attr1, attr2, description1, description2, \\\n",
    "        name1, name2, labels = data\n",
    "        \n",
    "        output = model(main1.to(device), main2.to(device),\n",
    "            not_main1.to(device), not_main2.to(device),\n",
    "            attr1.to(device), attr2.to(device), description1.to(device),\n",
    "            description2.to(device), name1.to(device), name2.to(device))\n",
    "        \n",
    "        loss = criterion(output, labels.to(device))\n",
    "        y_pred = np.argmax(F.softmax(output).cpu().detach().numpy(), axis=1)\n",
    "        preds = (y_pred > 0.5).astype(int)\n",
    "        precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "        test_auc += auc(recall, precision)\n",
    "        test_losses += loss.item()\n",
    "\n",
    "n3 = len(test_loader)\n",
    "print(f'Test PR-AUC: {test_auc / n3}. Loss: {test_losses / n3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(emb1, emb2, length, n):\n",
    "    dot = []\n",
    "    for i in range(n):\n",
    "        dot.append(np.dot(emb1[i], emb2[i]) / np.sqrt(length))\n",
    "    return np.array(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(df):\n",
    "    n = len(df)\n",
    "    len_image = 128\n",
    "    len_description = 312\n",
    "    len_name = 64\n",
    "    len_chars = 512\n",
    "\n",
    "    emb1 = np.concatenate(df.main1.to_numpy(), axis=0).reshape(n, len_image)\n",
    "    emb2 = np.concatenate(df.main2.to_numpy(), axis=0).reshape(n, len_image)\n",
    "    embedding1, embedding2 = torch.Tensor(emb1), torch.Tensor(emb2)\n",
    "    df['main_cos_distance'] = F.cosine_similarity(embedding1, embedding2).numpy()\n",
    "    df['main_eucl_distance'] = F.pairwise_distance(embedding1, embedding2).numpy()\n",
    "    df['main_dot_distance'] = dot_product(emb1, emb2, len_image, n)\n",
    "\n",
    "    emb1 = np.concatenate(df.not_main1.to_numpy(), axis=0).reshape(n, len_image)\n",
    "    emb2 = np.concatenate(df.not_main2.to_numpy(), axis=0).reshape(n, len_image)\n",
    "    embedding1, embedding2 = torch.Tensor(emb1), torch.Tensor(emb2)\n",
    "    df['not_main_cos_distance'] = F.cosine_similarity(embedding1, embedding2).numpy()\n",
    "    df['not_main_eucl_distance'] = F.pairwise_distance(embedding1, embedding2).numpy()\n",
    "    df['not_main_dot_distance'] = dot_product(emb1, emb2, len_image, n)\n",
    "    \n",
    "    emb1 = np.concatenate(df.name1.to_numpy(), axis=0).reshape(n, len_name)\n",
    "    emb2 = np.concatenate(df.name2.to_numpy(), axis=0).reshape(n, len_name)\n",
    "    name1, name2 = torch.Tensor(emb1), torch.Tensor(emb2)\n",
    "    df['name_cos_distance'] =  F.cosine_similarity(name1, name2).numpy()\n",
    "    df['name_eucl_distance'] = F.pairwise_distance(name1, name2).numpy()\n",
    "    df['name_dot_distance'] = dot_product(emb1, emb2, len_name, n)\n",
    "\n",
    "    emb1 = np.concatenate(df.description1.to_numpy(), axis=0).reshape(n, len_description)\n",
    "    emb2 = np.concatenate(df.description2.to_numpy(), axis=0).reshape(n, len_description)\n",
    "    description1, description2 = torch.Tensor(emb1), torch.Tensor(emb2)\n",
    "    df['description_cos_distance'] = F.cosine_similarity(description1, description2).numpy()\n",
    "    df['description_eucl_distance'] = F.pairwise_distance(description1, description2).numpy()\n",
    "    df['description_dot_distance'] = dot_product(emb1, emb2, len_description, n)\n",
    "\n",
    "    emb1 = np.concatenate(df.characters1.to_numpy(), axis=0).reshape(n, len_chars)\n",
    "    emb2 = np.concatenate(df.characters2.to_numpy(), axis=0).reshape(n, len_chars)\n",
    "    chars1, chars2 = torch.Tensor(emb1), torch.Tensor(emb2)\n",
    "    df['chars_cos_distance'] = F.cosine_similarity(description1, description2).numpy()\n",
    "    df['chars_eucl_distance'] = F.pairwise_distance(description1, description2).numpy()\n",
    "    df['chars_dot_distance'] = dot_product(emb1, emb2, len_chars, n)\n",
    "\n",
    "    return df[['variantid1', 'variantid2', 'target', 'main_cos_distance', 'main_eucl_distance', 'main_dot_distance', 'not_main_cos_distance', 'not_main_eucl_distance', 'not_main_dot_distance', \\\n",
    "              'name_cos_distance', 'name_eucl_distance', 'name_dot_distance', 'description_cos_distance', 'description_eucl_distance', 'description_dot_distance', \\\n",
    "              'chars_cos_distance', 'chars_eucl_distance', 'chars_dot_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.read_parquet('data/processed/merged.parquet')\n",
    "df = distances(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LightAutoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TARGET_NAME = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=df['target'],\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_data.columns.values[3:]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_data[columns] = scaler.fit_transform(train_data[columns])\n",
    "test_data[columns] = scaler.fit_transform(test_data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': 'target',\n",
    "        'drop': ['variantid1', 'variantid2']}\n",
    "\n",
    "task = Task('binary', loss='logloss', metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task=task,\n",
    "    gpu_ids='0',\n",
    "    cpu_limit = N_THREADS,\n",
    "    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = automl.fit_predict(train_data, roles=roles, verbose=1)\n",
    "test_predictions = automl.predict(test_data)\n",
    "not_nan = np.any(~np.isnan(train_predictions.data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_preds = train_data[roles['target']].values[not_nan], train_predictions.data[not_nan][:, 0]\n",
    "test_labels, test_preds = test_data[roles['target']].values, test_predictions.data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(automl, 'LAMl.pkl')\n",
    "#automl=joblib.load(‘model.pkl’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = (train_preds > 0.5).astype(int)\n",
    "test_preds = (test_preds > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(labels, preds):\n",
    "    precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "    return auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train PR-AUC: \", pr_auc(train_labels, train_preds))\n",
    "print(\"Test PR-AUC: \", pr_auc(test_labels, test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
